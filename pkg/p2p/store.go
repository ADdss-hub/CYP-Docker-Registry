// Package p2p æä¾›P2P Blobå­˜å‚¨å®ç°
package p2p

import (
	"fmt"
	"io"
	"os"
	"path/filepath"
	"sync"

	"go.uber.org/zap"
)

// FileBlobStore åŸºäºæ–‡ä»¶ç³»ç»Ÿçš„Blobå­˜å‚¨
type FileBlobStore struct {
	basePath string
	logger   *zap.Logger
	mu       sync.RWMutex
}

// NewFileBlobStore åˆ›å»ºæ–‡ä»¶Blobå­˜å‚¨
func NewFileBlobStore(basePath string, logger *zap.Logger) (*FileBlobStore, error) {
	// ç¡®ä¿ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(basePath, 0755); err != nil {
		return nil, fmt.Errorf("åˆ›å»ºå­˜å‚¨ç›®å½•å¤±è´¥: %w", err)
	}

	return &FileBlobStore{
		basePath: basePath,
		logger:   logger,
	}, nil
}

// Has æ£€æŸ¥æ˜¯å¦å­˜åœ¨Blob
func (s *FileBlobStore) Has(digest string) (bool, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	path := s.blobPath(digest)
	_, err := os.Stat(path)
	if err == nil {
		return true, nil
	}
	if os.IsNotExist(err) {
		return false, nil
	}
	return false, err
}

// Get è·å–Blob
func (s *FileBlobStore) Get(digest string) (io.ReadCloser, int64, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	path := s.blobPath(digest)
	info, err := os.Stat(path)
	if err != nil {
		if os.IsNotExist(err) {
			return nil, 0, fmt.Errorf("blobä¸å­˜åœ? %s", digest)
		}
		return nil, 0, err
	}

	file, err := os.Open(path)
	if err != nil {
		return nil, 0, err
	}

	return file, info.Size(), nil
}

// Put å­˜å‚¨Blob
func (s *FileBlobStore) Put(digest string, reader io.Reader, size int64) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	path := s.blobPath(digest)

	// ç¡®ä¿ç›®å½•å­˜åœ¨
	dir := filepath.Dir(path)
	if err := os.MkdirAll(dir, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºç›®å½•å¤±è´¥: %w", err)
	}

	// å†™å…¥ä¸´æ—¶æ–‡ä»¶
	tmpPath := path + ".tmp"
	file, err := os.Create(tmpPath)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤±è´¥: %w", err)
	}

	written, err := io.Copy(file, reader)
	file.Close()
	if err != nil {
		os.Remove(tmpPath)
		return fmt.Errorf("å†™å…¥æ•°æ®å¤±è´¥: %w", err)
	}

	if size > 0 && written != size {
		os.Remove(tmpPath)
		return fmt.Errorf("æ•°æ®å¤§å°ä¸åŒ¹é…? æœŸæœ› %d, å®é™… %d", size, written)
	}

	// é‡å‘½åä¸ºæœ€ç»ˆæ–‡ä»?
	if err := os.Rename(tmpPath, path); err != nil {
		os.Remove(tmpPath)
		return fmt.Errorf("é‡å‘½åæ–‡ä»¶å¤±è´? %w", err)
	}

	s.logger.Debug("å­˜å‚¨BlobæˆåŠŸ", zap.String("digest", digest), zap.Int64("size", written))
	return nil
}

// Delete åˆ é™¤Blob
func (s *FileBlobStore) Delete(digest string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	path := s.blobPath(digest)
	if err := os.Remove(path); err != nil && !os.IsNotExist(err) {
		return fmt.Errorf("åˆ é™¤Blobå¤±è´¥: %w", err)
	}

	s.logger.Debug("åˆ é™¤BlobæˆåŠŸ", zap.String("digest", digest))
	return nil
}

// List åˆ—å‡ºæ‰€æœ‰Blob
func (s *FileBlobStore) List() ([]string, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	var digests []string

	err := filepath.Walk(s.basePath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if info.IsDir() {
			return nil
		}

		// ä»è·¯å¾„æå–digest
		rel, err := filepath.Rel(s.basePath, path)
		if err != nil {
			return nil
		}

		// è·³è¿‡ä¸´æ—¶æ–‡ä»¶
		if filepath.Ext(rel) == ".tmp" {
			return nil
		}

		digests = append(digests, rel)
		return nil
	})

	return digests, err
}

// Size è·å–å­˜å‚¨å¤§å°
func (s *FileBlobStore) Size() (int64, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	var totalSize int64

	err := filepath.Walk(s.basePath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.IsDir() {
			totalSize += info.Size()
		}
		return nil
	})

	return totalSize, err
}

// Count è·å–Blobæ•°é‡
func (s *FileBlobStore) Count() (int, error) {
	digests, err := s.List()
	if err != nil {
		return 0, err
	}
	return len(digests), nil
}

// blobPath è·å–Blobæ–‡ä»¶è·¯å¾„
func (s *FileBlobStore) blobPath(digest string) string {
	// ä½¿ç”¨digestçš„å‰ä¸¤ä¸ªå­—ç¬¦ä½œä¸ºå­ç›®å½•ï¼Œé¿å…å•ç›®å½•æ–‡ä»¶è¿‡å¤?
	if len(digest) > 2 {
		return filepath.Join(s.basePath, digest[:2], digest)
	}
	return filepath.Join(s.basePath, digest)
}

// MemoryBlobStore å†…å­˜Blobå­˜å‚¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰
type MemoryBlobStore struct {
	blobs map[string][]byte
	mu    sync.RWMutex
}

// NewMemoryBlobStore åˆ›å»ºå†…å­˜Blobå­˜å‚¨
func NewMemoryBlobStore() *MemoryBlobStore {
	return &MemoryBlobStore{
		blobs: make(map[string][]byte),
	}
}

// Has æ£€æŸ¥æ˜¯å¦å­˜åœ¨Blob
func (s *MemoryBlobStore) Has(digest string) (bool, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	_, exists := s.blobs[digest]
	return exists, nil
}

// Get è·å–Blob
func (s *MemoryBlobStore) Get(digest string) (io.ReadCloser, int64, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	data, exists := s.blobs[digest]
	if !exists {
		return nil, 0, fmt.Errorf("blobä¸å­˜åœ? %s", digest)
	}

	return io.NopCloser(NewBytesReader(data)), int64(len(data)), nil
}

// Put å­˜å‚¨Blob
func (s *MemoryBlobStore) Put(digest string, reader io.Reader, size int64) error {
	data, err := io.ReadAll(reader)
	if err != nil {
		return err
	}

	s.mu.Lock()
	s.blobs[digest] = data
	s.mu.Unlock()

	return nil
}

// Delete åˆ é™¤Blob
func (s *MemoryBlobStore) Delete(digest string) error {
	s.mu.Lock()
	delete(s.blobs, digest)
	s.mu.Unlock()

	return nil
}

// List åˆ—å‡ºæ‰€æœ‰Blob
func (s *MemoryBlobStore) List() ([]string, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	digests := make([]string, 0, len(s.blobs))
	for digest := range s.blobs {
		digests = append(digests, digest)
	}
	return digests, nil
}

// BytesReader å­—èŠ‚è¯»å–å™?
type BytesReader struct {
	data   []byte
	offset int
}

// NewBytesReader åˆ›å»ºå­—èŠ‚è¯»å–å™?
func NewBytesReader(data []byte) *BytesReader {
	return &BytesReader{data: data}
}

// Read è¯»å–æ•°æ®
func (r *BytesReader) Read(p []byte) (int, error) {
	if r.offset >= len(r.data) {
		return 0, io.EOF
	}

	n := copy(p, r.data[r.offset:])
	r.offset += n
	return n, nil
}

// CachedBlobStore å¸¦ç¼“å­˜çš„Blobå­˜å‚¨
type CachedBlobStore struct {
	primary   BlobStore
	cache     *MemoryBlobStore
	maxCache  int64
	cacheSize int64
	logger    *zap.Logger
	mu        sync.RWMutex
}

// NewCachedBlobStore åˆ›å»ºå¸¦ç¼“å­˜çš„Blobå­˜å‚¨
func NewCachedBlobStore(primary BlobStore, maxCache int64, logger *zap.Logger) *CachedBlobStore {
	return &CachedBlobStore{
		primary:  primary,
		cache:    NewMemoryBlobStore(),
		maxCache: maxCache,
		logger:   logger,
	}
}

// Has æ£€æŸ¥æ˜¯å¦å­˜åœ¨Blob
func (s *CachedBlobStore) Has(digest string) (bool, error) {
	// å…ˆæ£€æŸ¥ç¼“å­?
	if has, _ := s.cache.Has(digest); has {
		return true, nil
	}
	return s.primary.Has(digest)
}

// Get è·å–Blob
func (s *CachedBlobStore) Get(digest string) (io.ReadCloser, int64, error) {
	// å…ˆä»ç¼“å­˜è·å–
	if reader, size, err := s.cache.Get(digest); err == nil {
		s.logger.Debug("ä»ç¼“å­˜è·å–Blob", zap.String("digest", digest))
		return reader, size, nil
	}

	// ä»ä¸»å­˜å‚¨è·å–
	reader, size, err := s.primary.Get(digest)
	if err != nil {
		return nil, 0, err
	}

	// å¦‚æœå¤§å°åˆé€‚ï¼ŒåŠ å…¥ç¼“å­˜
	if size < s.maxCache/10 { // å•ä¸ªæ–‡ä»¶ä¸è¶…è¿‡ç¼“å­˜çš„10%
		go s.addToCache(digest, reader, size)
	}

	return reader, size, nil
}

// addToCache æ·»åŠ åˆ°ç¼“å­?
func (s *CachedBlobStore) addToCache(digest string, reader io.ReadCloser, size int64) {
	s.mu.Lock()
	defer s.mu.Unlock()

	// æ£€æŸ¥ç¼“å­˜ç©ºé—?
	if s.cacheSize+size > s.maxCache {
		return // ç¼“å­˜å·²æ»¡
	}

	// è¯»å–æ•°æ®
	data, err := io.ReadAll(reader)
	reader.Close()
	if err != nil {
		return
	}

	// å­˜å…¥ç¼“å­˜
	s.cache.Put(digest, NewBytesReader(data), size)
	s.cacheSize += size
}

// Put å­˜å‚¨Blob
func (s *CachedBlobStore) Put(digest string, reader io.Reader, size int64) error {
	return s.primary.Put(digest, reader, size)
}

// Delete åˆ é™¤Blob
func (s *CachedBlobStore) Delete(digest string) error {
	s.cache.Delete(digest)
	return s.primary.Delete(digest)
}

// List åˆ—å‡ºæ‰€æœ‰Blob
func (s *CachedBlobStore) List() ([]string, error) {
	return s.primary.List()
}

// ClearCache æ¸…ç©ºç¼“å­˜
func (s *CachedBlobStore) ClearCache() {
	s.mu.Lock()
	defer s.mu.Unlock()

	s.cache = NewMemoryBlobStore()
	s.cacheSize = 0
}
